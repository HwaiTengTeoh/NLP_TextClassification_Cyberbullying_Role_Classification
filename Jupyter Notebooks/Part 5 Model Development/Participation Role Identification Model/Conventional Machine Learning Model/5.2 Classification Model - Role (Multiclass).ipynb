{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63d1fce0",
   "metadata": {},
   "source": [
    "<div class=\"alert\" style=\"background-color:#fff; color:white; padding:0px 10px; border-radius:5px;\"><h1 style='margin:15px 15px; color:#7bc043; font-size:40px'>5.2 Classification Model - Role (Multiclass) </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091042cf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#7bc043; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>Import Libraries or Modules </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "089d831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "%matplotlib inline\n",
    "\n",
    "# Begin Python Imports\n",
    "import datetime, warnings, scipy\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Visualization \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "# Progress bar\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "# Modelling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    StratifiedShuffleSplit,\n",
    "    GridSearchCV,\n",
    "    cross_val_score\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score, \n",
    "    accuracy_score, \n",
    "    confusion_matrix, \n",
    "    classification_report, \n",
    "    plot_confusion_matrix,\n",
    "    plot_precision_recall_curve\n",
    ")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767cd4d1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#7bc043; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>Train and Test Classifier</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec783f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate classifier\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "lr = LogisticRegression(n_jobs=-1,multi_class='multinomial')\n",
    "svc = LinearSVC(random_state=1127,multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3308e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnb = MultinomialNB()\n",
    "# xgb = XGBClassifier(tree_method='gpu_hist', random_state=1127)\n",
    "\n",
    "# # get a stacking ensemble of models\n",
    "# def get_stacking():\n",
    "#     # define the base models\n",
    "#     level0 = list()\n",
    "#     level0.append(('LogisticRegression', lr))\n",
    "#     level0.append(('LibSVC', svc))\n",
    "#     # level0.append(('MultinomialNaiveBayes', mnb))\n",
    "#     # define meta learner model\n",
    "#     level1 = lr\n",
    "#     # define the stacking ensemble\n",
    "#     model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5, n_jobs=-1)\n",
    "#     return model\n",
    "\n",
    "# stacking = get_stacking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea45be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# Train and Test Classifiers #\n",
    "##############################\n",
    "def automate_result(df='amica_data_clean_with_stopword',sampling='original',sampling_ratio=1):\n",
    "    \n",
    "    ####################\n",
    "    # Reset Processing #\n",
    "    ####################\n",
    "    # first check whether file exists or not\n",
    "    # calling remove method to delete the csv file\n",
    "    # in remove method you need to pass file name and type\n",
    "    \n",
    "    task = 'amica_role_classification'\n",
    "    file = task + '/' + df + '/results/results_' + sampling + '_sample.csv'\n",
    "    #file = df + '/results/results_all.csv'\n",
    "    if(os.path.exists(file) and os.path.isfile(file)):\n",
    "        os.remove(file)\n",
    "        print(\"File deleted\")\n",
    "    else:\n",
    "        print(\"File cleared\")\n",
    "     \n",
    "    \n",
    "    ########################\n",
    "    # Train and Test Model #\n",
    "    ########################\n",
    "    # Note    \n",
    "    # classifier_name and pipeline\n",
    "    # feature_name and X\n",
    "    \n",
    "    def run_model(classifier_name, feature_name, splits, X, Y, pipeline, average_method,target_label):\n",
    "        \n",
    "        # Instantiate \n",
    "        # kfold = StratifiedShuffleSplit(n_splits=splits, test_size=0.1, random_state=1127)\n",
    "        kfold = StratifiedKFold(n_splits=splits, shuffle=True, random_state=1127)\n",
    "        accuracy = []\n",
    "        precision = []\n",
    "        recall = []\n",
    "        f1 = []\n",
    "        auc = []\n",
    "        \n",
    "        record_cols = [\"sampling_method\",\"classifier\",\"feature\",\n",
    "                       \"accuracy\",\"accuracy_std\",\n",
    "                       \"precision\",\"precision_std\",\n",
    "                       \"recall\",\"recall_std\",\n",
    "                       \"f1\",\"f1_std\",\n",
    "                       \"auc\",\"auc_std\"]\n",
    "                \n",
    "             \n",
    "        # Run cross-validation\n",
    "        print(\"[\"+ sampling + \", \" + classifier_name + \"] Developing Model and Generating Metrics for features: \" + feature_name)\n",
    "        for train, test in tqdm(kfold.split(X, Y)):\n",
    "\n",
    "            # Train and fit model\n",
    "            model_fit = pipeline.fit(X[train], Y[train])\n",
    "            prediction = model_fit.predict(X[test])\n",
    "\n",
    "            # Compute metrics\n",
    "            scores = model_fit.score(X[test],Y[test])\n",
    "            accuracy.append(scores * 100)\n",
    "            if target_label == None:\n",
    "                precision.append(precision_score(Y[test], prediction, average=average_method)*100)\n",
    "                recall.append(recall_score(Y[test], prediction, average=average_method)*100)\n",
    "                f1.append(f1_score(Y[test], prediction, average=average_method)*100)\n",
    "                #auc.append(roc_auc_score(Y[test], model_fit.decision_function(X[test]), average=None)*100)\n",
    "            else:\n",
    "                precision.append(precision_score(Y[test], prediction, average=average_method, pos_label=target_label)*100)\n",
    "                recall.append(recall_score(Y[test], prediction, average=average_method, pos_label=target_label)*100)\n",
    "                f1.append(f1_score(Y[test], prediction, average=average_method, pos_label=target_label)*100)\n",
    "                #auc.append(roc_auc_score(Y[test], model_fit.decision_function(X[test]), average=average_method)*100)\n",
    "                \n",
    "        record = zip([sampling],\n",
    "                     [classifier_name], [feature_name],\n",
    "                     [np.mean(accuracy)], [np.std(accuracy)],\n",
    "                     [np.mean(precision)], [np.std(precision)] ,               \n",
    "                     [np.mean(recall)], [np.std(recall)] ,               \n",
    "                     [np.mean(f1)], [np.std(f1)],               \n",
    "                     [np.mean(auc)], [np.std(auc)]                \n",
    "                    ) \n",
    "\n",
    "        df = pd.DataFrame(record, columns=record_cols)\n",
    "        \n",
    "        df.to_csv(file,mode='a', header=(index==0))\n",
    "\n",
    "        \n",
    "        \n",
    "    #########################\n",
    "    # Classifier Dictionary #\n",
    "    #########################\n",
    "\n",
    "    classifier_dict = { 'LogisticRegression': lr,\n",
    "                        'LibSVC': svc\n",
    "                        \n",
    "                        }\n",
    "    \n",
    "        \n",
    "    \n",
    "    #######################\n",
    "    # Features Dictionary #\n",
    "    #######################\n",
    "    # Load Pickle files for X feature vectors\n",
    "    feature_location = 'amica_binary_classification'\n",
    "    path = feature_location + '\\\\' + df + '\\\\features\\\\selected'\n",
    "    all_files = glob.glob(path + \"/X*.pkl\")\n",
    "    feature_dict = {}\n",
    "\n",
    "    for file_ in all_files:\n",
    "        # temp = file_.split('\\\\')[-1].split('.')[0]\n",
    "        temp = file_.split('\\\\')[-1].split('.')[0].split(\"_\")[-1] # e.g X_AllTextual.pkl\n",
    "        \n",
    "        with open(file_,'rb') as f:\n",
    "            x = pickle.load(f)\n",
    "            feature_dict[temp]  = x\n",
    "    \n",
    "    \n",
    "    \n",
    "    ################\n",
    "    # Target Label #\n",
    "    ################\n",
    "    # Load Pickle file for Y label\n",
    "    \n",
    "    with open(task + '\\\\' + df + '\\\\target_class\\\\Y_role.pkl','rb') as f:\n",
    "        Y_label = pickle.load(f)\n",
    "    df= pd.DataFrame(list(Y_label))\n",
    "    print(df[0].value_counts())\n",
    "    \n",
    "    \n",
    "    ########################\n",
    "    # Run through the loop #\n",
    "    ########################\n",
    "   \n",
    "    index = 0 # Initialization\n",
    "    for classifier in classifier_dict.keys():\n",
    "        \n",
    "        # Selection of Pipeline by sampling method \n",
    "        if sampling == \"original\":\n",
    "            selected_pipeline = Pipeline([\n",
    "                                          ('classifier', classifier_dict[classifier])])\n",
    "\n",
    "        elif sampling == \"oversampling\":\n",
    "            selected_pipeline =  make_pipeline( \n",
    "                                               RandomOverSampler(random_state=1127,sampling_strategy=sampling_ratio),\n",
    "                                               scaler,\n",
    "                                               classifier_dict[classifier])\n",
    "            \n",
    "        elif sampling == \"smote\":\n",
    "            selected_pipeline =  make_pipeline(\n",
    "                                               SMOTE(random_state=1127,sampling_strategy=sampling_ratio),\n",
    "                                               scaler,\n",
    "                                               classifier_dict[classifier])     \n",
    "        elif sampling == \"downsampling\":\n",
    "            selected_pipeline = make_pipeline( \n",
    "                                              RandomUnderSampler(random_state=1127,sampling_strategy=sampling_ratio),\n",
    "                                              scaler,\n",
    "                                              classifier_dict[classifier])\n",
    "\n",
    "        for feature in tqdm(feature_dict.keys()):\n",
    "            X_feature = feature_dict[feature]\n",
    "            run_model(classifier_name=classifier, \n",
    "                      feature_name=feature, \n",
    "                      splits=10, \n",
    "                      X=X_feature, \n",
    "                      Y=Y_label, \n",
    "                      pipeline = selected_pipeline, \n",
    "                      average_method = 'macro', # macro for multiclass, binary for binary classification\n",
    "                      target_label = None) # Specify Cyberbullying for binary classification\n",
    "            index = index + 1\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7a62f7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File deleted\n",
      "0    106872\n",
      "1      3596\n",
      "2      1354\n",
      "3       425\n",
      "Name: 0, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[downsampling, LogisticRegression] Developing Model and Generating Metrics for features: CountVecWordCharAllTextStatSentimentAllDistilBertEmbeddingPycholinguisticLIWC22EmpathTermListsRatioToxicityMBTI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [01:51, 111.57s/it]\u001b[A\n",
      "2it [03:38, 109.01s/it]\u001b[A\n",
      "3it [05:20, 105.81s/it]\u001b[A\n",
      "4it [07:04, 104.85s/it]\u001b[A\n",
      "5it [08:44, 103.26s/it]\u001b[A\n",
      "6it [10:24, 102.06s/it]\u001b[A\n",
      "7it [12:01, 100.38s/it]\u001b[A\n",
      "8it [13:41, 100.42s/it]\u001b[A\n",
      "9it [15:21, 100.13s/it]\u001b[A\n",
      "10it [17:02, 102.29s/it]\u001b[A\n",
      " 50%|█████     | 1/2 [17:03<17:03, 1023.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[downsampling, LogisticRegression] Developing Model and Generating Metrics for features: CountVecWordCharAllTextStatSentimentAllDistilBertEmbeddingPycholinguisticLIWC22EmpathToxicityMBTI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [01:44, 104.06s/it]\u001b[A\n",
      "2it [03:21, 100.17s/it]\u001b[A\n",
      "3it [04:58, 98.79s/it] \u001b[A\n",
      "4it [06:36, 98.38s/it]\u001b[A\n",
      "5it [08:14, 98.40s/it]\u001b[A\n",
      "6it [09:50, 97.61s/it]\u001b[A\n",
      "7it [11:27, 97.25s/it]\u001b[A\n",
      "8it [13:06, 97.70s/it]\u001b[A\n",
      "9it [14:42, 97.15s/it]\u001b[A\n",
      "10it [16:20, 98.03s/it]\u001b[A\n",
      "100%|██████████| 2/2 [33:23<00:00, 1001.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# Data 1: 'amica_data_clean_with_stopword'\n",
    "############################################\n",
    "\n",
    "automate_result(df='amica_data_clean_with_stopword',sampling='downsampling',sampling_ratio={0:33363})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7050abe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
